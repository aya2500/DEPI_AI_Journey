{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d25d89a4",
   "metadata": {},
   "source": [
    "# Predicting Loan Approval (Kaggle-ready)\n",
    "\n",
    "Notebook prepared to run on Kaggle. It includes full preprocessing, baseline models, GridSearchCV experiments, evaluation metrics and plots. Put the `loan_data.csv` dataset file in the notebook dataset folder on Kaggle or update the path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad7ed56",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "This notebook uses: `pandas`, `numpy`, `scikit-learn`, `matplotlib`, `seaborn`, `joblib`.\n",
    "\n",
    "Kaggle environment usually has these preinstalled. For local runs, use the included `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b993817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "import joblib\n",
    "sns.set(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9158e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (auto-detect for local or Kaggle)\n",
    "import os\n",
    "from glob import glob\n",
    "csv_candidates = []\n",
    "\n",
    "# 1) Local file in working dir\n",
    "local_path = \"loan_data.csv\"\n",
    "if os.path.exists(local_path):\n",
    "    csv_candidates.append(local_path)\n",
    "\n",
    "# 2) Look for common Kaggle dataset path(s)\n",
    "kaggle_base = \"/kaggle/input\"\n",
    "if os.path.exists(kaggle_base):\n",
    "    # search for any csv under /kaggle/input that looks like loan data\n",
    "    for p in glob(os.path.join(kaggle_base, \"**\", \"*.csv\"), recursive=True):\n",
    "        # heuristics: filename contains 'loan' OR parent folder contains 'loan'\n",
    "        fname = os.path.basename(p).lower()\n",
    "        if 'loan' in fname or 'loan' in p.lower():\n",
    "            csv_candidates.append(p)\n",
    "\n",
    "# 3) As a fallback, add any csv in working dir\n",
    "for p in glob(\"*.csv\"):\n",
    "    if p not in csv_candidates:\n",
    "        csv_candidates.append(p)\n",
    "\n",
    "if not csv_candidates:\n",
    "    print(\"No CSV files found. Please upload 'loan_data.csv' to the notebook directory or add the Kaggle dataset via Add Data.\")\n",
    "    df = None\n",
    "else:\n",
    "    # pick the first candidate (most likely match); show all found for transparency\n",
    "    print(\"Found CSV candidates (in order):\")\n",
    "    for i,p in enumerate(csv_candidates):\n",
    "        print(f\"{i+1}. {p}\")\n",
    "    csv_path = csv_candidates[0]\n",
    "    print(\"\\nUsing:\", csv_path)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"Loaded dataframe shape:\", df.shape)\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da03537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick EDA\n",
    "try:\n",
    "    df.info()\n",
    "    display(df.isna().sum())\n",
    "    display(df.describe(include='all').T)\n",
    "except NameError:\n",
    "    print(\"Dataframe 'df' not loaded. Run the previous cell to load the CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9be93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing & Feature Engineering\n",
    "if 'df' in globals():\n",
    "    df = df.copy()\n",
    "    if 'Loan_ID' in df.columns:\n",
    "        df.drop('Loan_ID', axis=1, inplace=True)\n",
    "    # target\n",
    "    df['Loan_Status'] = df['Loan_Status'].map({'Y':1, 'N':0})\n",
    "    # Dependents: convert '3+' to '3'\n",
    "    if 'Dependents' in df.columns:\n",
    "        df['Dependents'] = df['Dependents'].replace('3+', '3')\n",
    "    # TotalIncome\n",
    "    df['TotalIncome'] = df.get('ApplicantIncome', 0) + df.get('CoapplicantIncome', 0)\n",
    "    # log transforms (handle missing safely)\n",
    "    df['LoanAmount_log'] = np.log1p(df['LoanAmount'].fillna(df['LoanAmount'].median()))\n",
    "    df['TotalIncome_log'] = np.log1p(df['TotalIncome'].fillna(df['TotalIncome'].median()))\n",
    "    display(df.head())\n",
    "else:\n",
    "    print('Load the data first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3719ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (70/30)\n",
    "if 'df' in globals():\n",
    "    target = 'Loan_Status'\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.30, random_state=42, stratify=y\n",
    "    )\n",
    "    print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
    "else:\n",
    "    print('Data not loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19feac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "numeric_features = [c for c in ['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','TotalIncome','LoanAmount_log','TotalIncome_log'] if c in X.columns]\n",
    "categorical_features = [c for c in X.columns if c not in numeric_features]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation helper\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, name=\"model\"):\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    metrics = {\n",
    "        'model': name,\n",
    "        'train_accuracy': accuracy_score(y_train, y_pred_train),\n",
    "        'test_accuracy': accuracy_score(y_test, y_pred_test),\n",
    "        'train_precision': precision_score(y_train, y_pred_train, zero_division=0),\n",
    "        'test_precision': precision_score(y_test, y_pred_test, zero_division=0),\n",
    "        'train_recall': recall_score(y_train, y_pred_train, zero_division=0),\n",
    "        'test_recall': recall_score(y_test, y_pred_test, zero_division=0),\n",
    "        'train_f1': f1_score(y_train, y_pred_train, zero_division=0),\n",
    "        'test_f1': f1_score(y_test, y_pred_test, zero_division=0),\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea32967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline models (fit and evaluate)\n",
    "models = {\n",
    "    'Logistic_L2': Pipeline(steps=[('pre', preprocessor), ('clf', LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000, random_state=42))]),\n",
    "    'DecisionTree': Pipeline(steps=[('pre', preprocessor), ('clf', DecisionTreeClassifier(random_state=42))]),\n",
    "    'RandomForest': Pipeline(steps=[('pre', preprocessor), ('clf', RandomForestClassifier(n_estimators=100, random_state=42))]),\n",
    "    'AdaBoost': Pipeline(steps=[('pre', preprocessor), ('clf', AdaBoostClassifier(n_estimators=50, random_state=42))]),\n",
    "    'SVM': Pipeline(steps=[('pre', preprocessor), ('clf', SVC(kernel='rbf', probability=True, random_state=42))]),\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, pipe in models.items():\n",
    "    try:\n",
    "        pipe.fit(X_train, y_train)\n",
    "        res = evaluate_model(pipe, X_train, X_test, y_train, y_test, name=name)\n",
    "        results.append(res)\n",
    "        print(name, \"done.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error for\", name, \":\", e)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29480520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices and classification reports\n",
    "for name, pipe in models.items():\n",
    "    try:\n",
    "        print('\\nModel:', name)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d')\n",
    "        plt.title(f'{name} - Confusion Matrix')\n",
    "        plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print('Error plotting for', name, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c20ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree visualization (shallow)\n",
    "try:\n",
    "    dt_pipe = models['DecisionTree']\n",
    "    dt = dt_pipe.named_steps['clf']\n",
    "    # feature names after preprocessing\n",
    "    cat_ohe = dt_pipe.named_steps['pre'].named_transformers_['cat'].named_steps['onehot']\n",
    "    cat_cols = list(cat_ohe.get_feature_names_out(dt_pipe.named_steps['pre'].transformers_[1][2]))\n",
    "    num_cols = [c for c in numeric_features]\n",
    "    feature_names = list(num_cols) + cat_cols\n",
    "    plt.figure(figsize=(18,10))\n",
    "    plot_tree(dt, feature_names=feature_names, class_names=['N','Y'], filled=True, max_depth=3)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('Decision tree plot error:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d13643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV - Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'clf__penalty': ['l1','l2','elasticnet'],\n",
    "    'clf__C': [0.01, 0.1, 1, 10],\n",
    "    'clf__solver': ['saga'],\n",
    "    'clf__l1_ratio': [0.0, 0.5, 1.0]\n",
    "}\n",
    "pipe_lr = Pipeline(steps=[('pre', preprocessor), ('clf', LogisticRegression(max_iter=5000, random_state=42))])\n",
    "grid_lr = GridSearchCV(pipe_lr, param_grid_lr, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "print('Best LR params:', grid_lr.best_params_)\n",
    "best_lr = grid_lr.best_estimator_\n",
    "res_lr = evaluate_model(best_lr, X_train, X_test, y_train, y_test, name='LogisticGrid')\n",
    "res_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV - Decision Tree\n",
    "param_grid_dt = {\n",
    "    'clf__criterion': ['gini','entropy'],\n",
    "    'clf__max_depth': [3,5,7,10, None],\n",
    "    'clf__min_samples_split': [2,5,10],\n",
    "    'clf__min_samples_leaf': [1,2,4]\n",
    "}\n",
    "pipe_dt = Pipeline(steps=[('pre', preprocessor), ('clf', DecisionTreeClassifier(random_state=42))])\n",
    "grid_dt = GridSearchCV(pipe_dt, param_grid_dt, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "print('Best DT params:', grid_dt.best_params_)\n",
    "best_dt = grid_dt.best_estimator_\n",
    "res_dt = evaluate_model(best_dt, X_train, X_test, y_train, y_test, name='DecisionTreeGrid')\n",
    "res_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV - Random Forest (smaller grid to save time)\n",
    "param_grid_rf = {\n",
    "    'clf__n_estimators': [100,200],\n",
    "    'clf__max_depth': [None, 5, 10],\n",
    "    'clf__min_samples_split': [2,5],\n",
    "}\n",
    "pipe_rf = Pipeline(steps=[('pre', preprocessor), ('clf', RandomForestClassifier(random_state=42))])\n",
    "grid_rf = GridSearchCV(pipe_rf, param_grid_rf, cv=4, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "print('Best RF params:', grid_rf.best_params_)\n",
    "best_rf = grid_rf.best_estimator_\n",
    "res_rf = evaluate_model(best_rf, X_train, X_test, y_train, y_test, name='RandomForestGrid')\n",
    "res_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f3a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV - AdaBoost\n",
    "param_grid_ab = {\n",
    "    'clf__n_estimators': [50,100,200],\n",
    "    'clf__learning_rate': [0.5,1.0,1.5]\n",
    "}\n",
    "pipe_ab = Pipeline(steps=[('pre', preprocessor), ('clf', AdaBoostClassifier(random_state=42))])\n",
    "grid_ab = GridSearchCV(pipe_ab, param_grid_ab, cv=4, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_ab.fit(X_train, y_train)\n",
    "print('Best AB params:', grid_ab.best_params_)\n",
    "best_ab = grid_ab.best_estimator_\n",
    "res_ab = evaluate_model(best_ab, X_train, X_test, y_train, y_test, name='AdaBoostGrid')\n",
    "res_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM (no GridSearch)\n",
    "pipe_svm = Pipeline(steps=[('pre', preprocessor), ('clf', SVC(kernel='rbf', probability=True, random_state=42))])\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "res_svm = evaluate_model(pipe_svm, X_train, X_test, y_train, y_test, name='SVM_RBF')\n",
    "res_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b947bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results (baseline + tuned)\n",
    "all_results = pd.DataFrame(results) if 'results' in globals() else pd.DataFrame()\n",
    "others = []\n",
    "for var in ['res_lr','res_dt','res_rf','res_ab','res_svm']:\n",
    "    if var in globals():\n",
    "        others.append(globals()[var])\n",
    "if len(others):\n",
    "    for r in others:\n",
    "        all_results = all_results.append(r, ignore_index=True)\n",
    "if not all_results.empty:\n",
    "    all_results = all_results.sort_values(by='test_f1', ascending=False).reset_index(drop=True)\n",
    "display(all_results)\n",
    "else:\n",
    "    print(\"No results to show yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec58c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model (example)\n",
    "if 'all_results' in globals() and not all_results.empty:\n",
    "    best_name = all_results.loc[0,'model']\n",
    "    print(\"Best model according to test_f1:\", best_name)\n",
    "    # Map names to estimators\n",
    "    names_map = {\n",
    "        'Logistic_L2': models.get('Logistic_L2'),\n",
    "        'DecisionTree': models.get('DecisionTree'),\n",
    "        'RandomForest': models.get('RandomForest'),\n",
    "        'AdaBoost': models.get('AdaBoost'),\n",
    "        'SVM': models.get('SVM'),\n",
    "        'LogisticGrid': globals().get('best_lr'),\n",
    "        'DecisionTreeGrid': globals().get('best_dt'),\n",
    "        'RandomForestGrid': globals().get('best_rf'),\n",
    "        'AdaBoostGrid': globals().get('best_ab'),\n",
    "        'SVM_RBF': globals().get('pipe_svm')\n",
    "    }\n",
    "    best_model = names_map.get(best_name)\n",
    "    if best_model is not None:\n",
    "        joblib.dump(best_model, 'best_model.joblib')\n",
    "        print('Saved best_model.joblib')\n",
    "    else:\n",
    "        print('Best model not found in map; save your preferred estimator manually.')\n",
    "else:\n",
    "    print('No results dataframe available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033c9522",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- Verify dataset upload on Kaggle (upload `loan_data.csv`).\n",
    "- Run cells sequentially.\n",
    "- Export results, download `best_model.joblib` if needed.\n",
    "\n",
    "---\n",
    "\n",
    "### To upload this notebook to Kaggle:\n",
    "1. Create a new Kaggle notebook, choose 'Upload' and upload this `.ipynb` file.\n",
    "2. Upload dataset file `loan_data.csv` to the notebook's dataset files or attach a dataset.\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
